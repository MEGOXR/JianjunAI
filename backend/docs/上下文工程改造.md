# 用户对话与记忆体验提升分析

## 零、架构决策：Responses API + 每轮重建 Context

### 最终决策：使用 Responses API（不依赖 previous_response_id）

经过深入分析和与 Tolan 架构对比，**我们决定使用 Responses API，但不使用 `previous_response_id`**：

#### 为什么选择 Responses API？

| 优势 | 说明 |
|------|------|
| **更好的 TTFT** | Responses API 在首字节延迟上有优化 |
| **更高的 Cache 命中率** | 即使每轮重建，静态部分（System Prompt）仍可缓存 |
| **支持更多参数** | 如 `store`、`reasoning` 等高级参数 |
| **统一的 API 体验** | 与 OpenAI/Azure 未来方向一致 |

#### 为什么不使用 `previous_response_id`？

| 问题 | 影响 |
|------|------|
| **动态 instructions 破坏 KV Cache** | 每轮 Tone/记忆检索结果变化 → KV Cache 失效 |
| **无法控制窗口大小** | 使用 `previous_response_id` 时 tokens 线性增长 |
| **与 Tolan 架构冲突** | Tolan 明确说 "rebuild context every turn" |

#### 成本分析

```
场景：100轮对话

方案A - Responses API + previous_response_id (❌ 不采用):
  Turn 1:   100 tokens
  Turn 50:  5000 tokens
  Turn 100: 10000 tokens
  总计: ~500,000 input tokens
  问题: 动态 context 导致 KV Cache 失效，无成本优势

方案B - Responses API + 每轮重建 (✅ 采用):
  每轮: ~3000-4000 tokens (summary + recent + dynamic)
  总计: ~350,000 input tokens
  优势: 可控窗口 + Responses API 的 TTFT 优化
```

#### Tolan 的做法（我们学习并超越）

> "Unlike many agents that cache prompts across multiple turns, Tolan **rebuilds its context window from scratch each turn**."

我们采用 **Responses API + 每轮重建 Context**，每轮包含：
- Chat summary（早期消息的压缩摘要）
- Raw messages since threshold（最近N条原始消息）
- Persona card
- Vector-retrieved memories
- Tone guidance

### 推荐架构：可控 Context Window (Tolan 方式)

```
┌─────────────────────────────────────────────────────────────────────┐
│                    每轮构建的 messages                               │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  ┌──────────────────────────────────────┐                           │
│  │ System Prompt (静态，~1000 tokens)   │                           │
│  ├──────────────────────────────────────┤                           │
│  │ [Chat Summary] (动态，~500 tokens)   │  ← 超过阈值时自动压缩      │
│  │ "用户之前咨询过隆鼻，关注术后恢复..."│                           │
│  ├──────────────────────────────────────┤                           │
│  │ [User Persona] (动态，~200 tokens)   │  ← 用户人设卡              │
│  │ "称呼: 小王, 关注点: 双眼皮..."      │                           │
│  ├──────────────────────────────────────┤                           │
│  │ [Tone Guidance] (动态，~100 tokens)  │  ← 根据情绪调整            │
│  │ "用户目前比较焦虑，请温和回复..."    │                           │
│  ├──────────────────────────────────────┤                           │
│  │ [Active Recall] (动态，~300 tokens)  │  ← 主动检索注入            │
│  │ "相关记忆: 用户3天前咨询过价格..."   │                           │
│  ├──────────────────────────────────────┤                           │
│  │ [Recent Messages] (原始，最近10-15轮)│  ← 原始对话                │
│  │ user: "..."                          │                           │
│  │ assistant: "..."                     │                           │
│  ├──────────────────────────────────────┤                           │
│  │ [Current User Input]                 │                           │
│  └──────────────────────────────────────┘                           │
│                                                                      │
│  总 tokens: ~3000-4000 (可控，不会无限增长)                          │
└─────────────────────────────────────────────────────────────────────┘
```

### 与记忆系统的集成

```
┌─────────────────────────────────────────────────────────────────────┐
│                    最终架构设计                                      │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  ┌──────────────────┐  ┌──────────────────┐  ┌──────────────────┐  │
│  │  Responses API   │  │    Memobase      │  │    Supabase      │  │
│  │ (每轮重建Context)│  │  (长期记忆)      │  │  (持久化存储)    │  │
│  │                  │  │                  │  │                  │  │
│  │ • 可控窗口大小   │  │ • 用户画像       │  │ • 完整消息备份   │  │
│  │ • Full Messages  │  │ • 语义检索       │  │ • 会话摘要       │  │
│  │ • 更好的TTFT     │  │ • 偏好记录       │  │ • 分析数据       │  │
│  └──────────────────┘  └──────────────────┘  └──────────────────┘  │
│           │                    │                     │              │
│           │        ┌───────────┴───────────┐         │              │
│           │        │                       │         │              │
│           ▼        ▼                       ▼         ▼              │
│  ┌─────────────────────────────────────────────────────────────┐   │
│  │              Enhanced Context (每轮重建)                    │   │
│  │                                                             │   │
│  │  System Prompt + Chat Summary + User Persona +              │   │
│  │  Tone Guidance + Active Recall + Recent Messages            │   │
│  └─────────────────────────────────────────────────────────────┘   │
└─────────────────────────────────────────────────────────────────────┘
```

### API 调用方式变更

从 `client.chat.completions.create()` 迁移到 `client.responses.create()`：

```javascript
// 旧方式 (Chat Completions)
const stream = await client.chat.completions.create({
  model: deployment,
  messages: messagesForLlm,
  stream: true,
  max_completion_tokens: 2000
});

// 新方式 (Responses API，不使用 previous_response_id)
const stream = await client.responses.create({
  model: deployment,
  input: messagesForLlm,  // 完整消息数组，每轮重建
  stream: true,
  max_output_tokens: 2000
  // 注意：不传 previous_response_id
});
```

**关键点**:
- 使用 `input` 参数传递完整的 messages 数组
- 不使用 `previous_response_id`，每轮重建上下文
- 保持可控的 Context Window 大小

---

## 一、当前项目每轮Prompt包含的信息

根据 `chatController.js:424-438` 的实现，当前每轮对话给LLM的prompt构建如下：

```
┌─────────────────────────────────────────────────────────────────┐
│  1. System Prompt (基础人设)                                      │
│     └─ 来源: prompts.json                                        │
│     └─ 内容: 角色定义、人设特点、回复风格、SEARCH工具说明             │
│                                                                   │
│  2. 用户记忆档案 (Memobase)                                        │
│     └─ 来源: memobaseService.buildEnhancedSystemPrompt()          │
│     └─ 内容: 用户画像(profiles) + 历史事件(events)                  │
│                                                                   │
│  3. 时间上下文                                                     │
│     └─ 当前日期时间: currentDateStr                                │
│     └─ 时间感知提示: timeAwarenessPrompt (超过24小时未访问时)       │
│                                                                   │
│  4. 对话历史                                                       │
│     └─ 最多31条消息 (~15轮)                                        │
│     └─ 来源: 内存缓存 / Supabase持久化                             │
│                                                                   │
│  5. 当前用户消息                                                   │
│     └─ 文本内容                                                    │
│     └─ 图片 (Vision API格式, 如有)                                 │
└─────────────────────────────────────────────────────────────────┘
```

---

## 二、Tolan架构核心组件 (基于OpenAI文章和图片)

### 图1: Tolan对话循环流程

```
                    ┌──────────────────┐
                    │ Recompute Persona │  ← 每轮重新计算
                    └────────┬─────────┘
                             │
        ┌────────────────────┼────────────────────┐
        │                    │                    │
        ▼                    ▼                    ▼
┌───────────────┐  ┌─────────────────┐  ┌────────────┐  ┌──────┐
│Chat summary + │  │User & Tolan     │  │  Memory    │  │ Tone │
│raw messages   │  │Personas +       │  │(vector DB) │  │      │
│since threshold│  │other context    │  │            │  │      │
└───────────────┘  └─────────────────┘  └────────────┘  └──────┘
        │                    │                    │           │
        └────────────────────┴────────────────────┴───────────┘
                             │
                             ▼
                    ┌──────────────────┐
                    │Generate Response │
                    └────────┬─────────┘
                             │
                             ▼
                    ┌──────────────────┐
                    │  User Response   │
                    └────────┬─────────┘
                             │
        ┌────────────────────┼────────────────────┐
        ▼                    ▼                    ▼
┌───────────────┐  ┌─────────────────┐  ┌──────────────────┐
│Re-summarize & │  │Extract memories │  │Derive updated    │
│compress history│ │                 │  │tone              │
└───────────────┘  └─────────────────┘  └──────────────────┘
       ↑                                         │
       └─────────────────────────────────────────┘
                    (反馈循环)
```

### 图2: 记忆检索与存储流程

**检索流程:**
```
User Message ──▶ Synthesize Questions ──▶ Embed & Query Vector DB
      │              │                            │
      │         (生成多个查询)               (并行检索)
      │              │                            │
      │              ▼                            ▼
      │    ┌─────────────────────────────────────────┐
      │    │   Merge results with Mean Reciprocal   │
      │    │              Rank (MRR)                 │
      │    └─────────────────────────────────────────┘
      │                       │
      │                       ▼
      │              ┌─────────────────┐
      └──────────────│Generate Response│
                     └─────────────────┘
```

**存储流程:**
```
User Message ──▶ Store ──▶ REFLECT ──▶ Cluster by kNN ──▶ COMPRESS
                                              │
                                              ▼
                              ┌──────────────────────────────┐
                              │ Combine, edit, refine        │
                              │ memories within cluster      │
                              └──────────────────────────────┘
```

### Tolan关键设计原则

1. **每轮重建上下文** - 不缓存prompt，每轮从头构建
2. **记忆是检索系统** - 高质量压缩 + 快速向量搜索
3. **sub-50ms记忆检索** - 使用Turbopuffer向量数据库
4. **主动合成问题** - 从用户消息生成多个检索query
5. **夜间压缩任务** - 移除低价值记录，解决矛盾
6. **动态Tone系统** - 监控情感氛围并调整回复风格

---

## 三、当前项目与Tolan的差距分析

| 维度 | 当前实现 | Tolan实现 | 差距评估 |
|------|----------|-----------|----------|
| **Persona** | 静态AI人设 | 动态User+AI Persona | ⚠️ 缺少用户人设 |
| **Memory检索** | 被动SEARCH标签触发 | 主动合成多问题检索 | ⚠️ 检索不够智能 |
| **Tone系统** | 无 | 动态情感氛围监控 | ❌ 完全缺失 |
| **对话摘要** | 仅会话结束时生成 | 持续摘要+原始消息混合 | ⚠️ 不够实时 |
| **记忆压缩** | 依赖Memobase flush | kNN聚类+夜间压缩 | ⚠️ 被动依赖 |
| **时间上下文** | ✅ 已有 | ✅ 相似 | ✓ 已实现 |
| **向量检索** | ✅ Memobase | ✅ Turbopuffer | ✓ 已实现 |

---

## 四、改进建议 (按优先级排序)

### P0: 核心体验提升

#### 1. 主动记忆检索 (Active Memory Recall)

**现状问题:** 当前记忆检索是被动的，依赖LLM输出`[SEARCH:]`标签

**Tolan方案:** 每轮自动从用户消息合成多个检索问题

**改进方案:**
```javascript
// 在每轮对话开始时，自动生成检索问题
async function synthesizeRetrievalQuestions(userMessage, conversationContext) {
  const questions = [
    `用户当前关心什么?`,          // 意图
    `用户之前提过这个话题吗?`,     // 历史
    `用户的偏好是什么?`           // 画像
  ];

  // 并行检索，MRR融合结果
  const results = await Promise.all(
    questions.map(q => memoryService.searchEvents(userId, q, 3))
  );

  return mergeWithMRR(results);
}
```

**关键文件:** `chatController.js:375-450`

---

#### 2. Tone系统 (情感氛围管理)

**现状问题:** 无论用户心情如何，AI回复风格固定

**Tolan方案:** 动态监控对话情感，调整回复风格

**改进方案:**
```javascript
// 新建 toneService.js
const TONE_DIMENSIONS = {
  energy: 'calm|neutral|energetic',    // 能量级别
  formality: 'casual|professional',     // 正式程度
  empathy: 'low|medium|high'           // 共情程度
};

async function deriveTone(messages) {
  // 分析最近N条消息的情感
  // 返回: { energy: 'calm', formality: 'casual', empathy: 'high' }
}

function applyToneToPrompt(basePrompt, tone) {
  // 注入风格指导
  return `${basePrompt}\n\n[Tone Guidance]:
当前用户情绪较低落，请用${tone.energy}的语气，
保持${tone.empathy}的共情度回复。`;
}
```

---

#### 3. 持续对话摘要 (Rolling Summary)

**现状问题:** 仅在会话结束时生成摘要，31条消息限制导致早期上下文丢失

**Tolan方案:** Chat summary + raw messages since summary threshold

**改进方案:**
```javascript
// 当消息数超过阈值时，触发摘要压缩
const SUMMARY_THRESHOLD = 15; // 15条消息后开始摘要

async function manageChatHistory(history) {
  if (history.length > SUMMARY_THRESHOLD) {
    // 保留最近10条原始消息
    const rawMessages = history.slice(-10);

    // 对更早的消息生成摘要
    const oldMessages = history.slice(0, -10);
    const summary = await generateRollingSummary(oldMessages);

    return [
      { role: 'system', content: `[对话摘要]: ${summary}` },
      ...rawMessages
    ];
  }
  return history;
}
```

---

### P1: 记忆质量提升

#### 4. 记忆压缩与聚类 (Memory Compression)

**现状问题:** Memobase的flush是黑盒，无法控制记忆质量

**Tolan方案:** kNN聚类 + 周期性压缩任务

**改进方案:**
```javascript
// 新建定时任务: memoryCompressionJob.js
async function compressUserMemories(userId) {
  const memories = await memobaseService.getAllMemories(userId);

  // 1. 聚类相似记忆
  const clusters = clusterByEmbedding(memories, { k: 5 });

  // 2. 合并/精炼每个聚类
  for (const cluster of clusters) {
    if (cluster.length > 3) {
      const refined = await refineMemoryCluster(cluster);
      await memobaseService.replaceMemories(cluster.ids, refined);
    }
  }

  // 3. 删除低价值记忆
  const lowValue = memories.filter(m => m.score < 0.3);
  await memobaseService.deleteMemories(lowValue.ids);
}

// 夜间执行
schedule.scheduleJob('0 3 * * *', compressUserMemories);
```

---

#### 5. 用户人设卡 (User Persona Card)

**现状问题:** 只有AI人设，没有动态用户人设

**Tolan方案:** 每轮重新计算User Persona

**改进方案:**
```javascript
// 从记忆中构建用户人设卡
async function buildUserPersona(userId) {
  const profile = await memobaseService.getUserProfile(userId);

  return {
    name: profile.extractedName || '用户',
    communicationStyle: profile.communicationPreference || 'neutral',
    primaryConcerns: profile.concerns || [],
    visitHistory: {
      totalVisits: profile.totalSessions,
      lastTopic: profile.lastTopic
    },
    emotionalState: profile.currentMood || 'neutral'
  };
}

// 注入到prompt
function injectUserPersona(prompt, persona) {
  return `${prompt}\n\n[用户画像]:
- 称呼: ${persona.name}
- 沟通风格偏好: ${persona.communicationStyle}
- 主要关注点: ${persona.primaryConcerns.join(', ')}
- 访问次数: ${persona.visitHistory.totalVisits}
- 当前情绪: ${persona.emotionalState}`;
}
```

---

## 五、实施路线图

### 阶段0: Responses API 迁移 + Rolling Summary ⭐ (最高优先级)
- [ ] 迁移 AzureLLMProvider 到 Responses API
- [ ] 实现 Rolling Summary 可控 Context Window
- [ ] 重构 chatController 消息构建逻辑

### 阶段1: 主动记忆检索 + User Persona
- [ ] 实现主动记忆检索 (synthesizeQuestions + MRR融合)
- [ ] 优化prompt结构，增加User Persona注入

### 阶段2: Tone情感系统
- [ ] 实现Tone系统 (情感分析 + 风格调整)
- [ ] 添加Tone反馈循环

### 阶段3: 长期优化 (持续)
- [ ] 实现记忆压缩定时任务
- [ ] A/B测试各项优化效果
- [ ] 基于用户反馈持续迭代

---

## 六、关键代码文件

| 文件路径 | 需要修改的内容 |
|----------|----------------|
| `backend/src/providers/azure/AzureLLMProvider.js` | **迁移到 Responses API**: 添加 `createResponseStream()` 方法 |
| `backend/src/controllers/chatController.js` | 主动检索逻辑、Tone注入、Rolling Summary、调用新API |
| `backend/src/services/memoryService.js` | 添加synthesizeQuestions、MRR融合 |
| `backend/src/services/toneService.js` | 新建 - 情感分析与风格调整 |
| `backend/src/services/rollingSummaryService.js` | 新建 - 实时摘要生成与管理 |
| `backend/src/services/memobaseService.js` | 添加记忆压缩、聚类方法 |
| `backend/config/prompts.json` | 添加Tone模板、User Persona模板 |

---

---

## 七、关键问题解答

### Q1: 主动记忆检索是否会增加延迟？如何处理？

**短答案**: 是的，会增加延迟，但业界有成熟的并行化和filler方案。

#### 方案A: 并行流水线 (推荐)

根据 [Meta REFRAG](https://bdtechtalks.com/2025/09/15/meta-refrag-llm-rag-optimization/) 和 RAGDoll 的研究：

```
用户发送消息
     │
     ├─────────────────┬──────────────────┐
     │                 │                  │
     ▼                 ▼                  ▼
┌─────────┐     ┌─────────────┐    ┌─────────────┐
│意图分析 │     │记忆检索(并行)│    │Tone分析     │
│(快速LLM)│     │~50-100ms    │    │(并行)       │
└────┬────┘     └──────┬──────┘    └──────┬──────┘
     │                 │                  │
     └─────────────────┴──────────────────┘
                       │
                       ▼
              ┌─────────────────┐
              │  主LLM生成回复   │
              │  (包含检索结果)  │
              └─────────────────┘
```

**关键点**: 检索和分析在用户消息到达后**立即并行启动**，不等待LLM开始生成。

#### 方案B: Filler + 流式输出

根据 [Sierra Voice Latency](https://sierra.ai/blog/voice-latency) 的实践：

```javascript
// 伪代码：Filler + 并行检索
async function handleMessage(userMessage) {
  // 1. 立即启动并行任务
  const retrievalPromise = retrieveMemories(userMessage);  // 异步
  const tonePromise = analyzeTone(userMessage);             // 异步

  // 2. 快速生成filler（可选，仅语音场景）
  // ws.send({ data: "让我想想..." });

  // 3. 等待并行任务完成（通常<100ms）
  const [memories, tone] = await Promise.all([retrievalPromise, tonePromise]);

  // 4. 构建增强prompt，开始流式生成
  const enhancedMessages = buildEnhancedMessages(baseMessages, memories, tone);
  const stream = await llm.stream(enhancedMessages);

  // 5. 流式输出
  for await (const chunk of stream) {
    ws.send({ data: chunk });
  }
}
```

#### 方案C: Speculative Pipelining (最激进)

```
用户消息 ───▶ 开始生成回复（无需等待）
              │
              │  ← 同时：后台检索记忆
              │  ← 如果检索到重要信息 → 中断并重新生成
              ▼
         输出回复
```

这种方案风险较高，但延迟最低。Tolan可能使用类似方案。

#### 本项目推荐方案

对于微信小程序（文字为主）场景，推荐 **方案A + 轻量filler**：

```javascript
// chatController.js 改造
timer.mark('开始并行检索');

// 并行启动三个任务
const [memories, tone, summaryNeeded] = await Promise.all([
  synthesizeAndRetrieve(userId, prompt),    // 合成问题 + 检索记忆
  analyzeTone(history.slice(-5)),           // 分析最近5条消息的情感
  checkSummaryThreshold(history)            // 检查是否需要压缩摘要
]);

timer.mark('并行检索完成', { memoryCount: memories.length });

// 构建增强消息
const enhancedMessages = buildMessages(history, memories, tone);
```

**预期延迟增量**: 50-150ms（向量检索 ~50ms，情感分析 ~100ms，并行执行）

---

### Q2: Tone情感系统如何实现？

根据 [Robylon](https://www.robylon.ai/blog/how-ai-chatbots-sound-so-human) 和 [Dialzara](https://dialzara.com/blog/top-7-sentiment-analysis-techniques-for-voice-ai) 的最佳实践：

#### Tone系统架构

```
                    ┌─────────────────────────────────────┐
                    │           Tone Service              │
                    └─────────────────────────────────────┘
                                    │
        ┌───────────────────────────┼───────────────────────────┐
        │                           │                           │
        ▼                           ▼                           ▼
┌───────────────┐          ┌───────────────┐          ┌───────────────┐
│ 情绪检测      │          │ 上下文追踪    │          │ 风格适配      │
│ (Emotion)     │          │ (Context)     │          │ (Adaptation)  │
│               │          │               │          │               │
│ - 焦虑        │          │ - 情绪轨迹    │          │ - 语气调整    │
│ - 兴奋        │          │ - 话题变化    │          │ - 措辞优化    │
│ - 困惑        │          │ - 参与度      │          │ - 共情表达    │
│ - 信任        │          │               │          │               │
└───────────────┘          └───────────────┘          └───────────────┘
```

#### 实现方案

```javascript
// services/toneService.js

const EMOTION_KEYWORDS = {
  anxiety: ['担心', '害怕', '紧张', '不安', '风险', '后悔'],
  excitement: ['期待', '想要', '终于', '迫不及待', '好想'],
  confusion: ['不懂', '什么意思', '搞不清', '迷茫', '不明白'],
  trust: ['相信', '放心', '专业', '感谢', '信任']
};

const TONE_TEMPLATES = {
  high_anxiety: {
    empathy: 'high',
    pace: 'slow',
    reassurance: true,
    prompt_suffix: `用户目前显得比较焦虑，请：
1. 用温和稳重的语气回复
2. 先表达理解和共情
3. 给出明确的、有安全感的建议
4. 避免使用可能引发更多担忧的词汇`
  },
  high_excitement: {
    empathy: 'medium',
    pace: 'normal',
    enthusiasm: true,
    prompt_suffix: `用户情绪积极，请：
1. 保持专业的同时呼应用户的热情
2. 给出详细的实用建议
3. 适当管理期望，提醒注意事项`
  },
  confusion: {
    empathy: 'medium',
    pace: 'slow',
    clarity: true,
    prompt_suffix: `用户似乎有些困惑，请：
1. 用简单易懂的语言解释
2. 分点列出关键信息
3. 主动询问哪里不清楚`
  },
  neutral: {
    empathy: 'medium',
    pace: 'normal',
    prompt_suffix: '' // 不需要额外调整
  }
};

/**
 * 分析对话情感
 * @param {Array} recentMessages - 最近N条消息
 * @returns {Object} tone配置
 */
async function analyzeTone(recentMessages) {
  // 方案1: 基于关键词的快速分析 (~10ms)
  const emotions = detectEmotions(recentMessages);

  // 方案2: 使用小型LLM进行深度分析 (~100ms，可选)
  // const emotions = await llmAnalyzeEmotion(recentMessages);

  // 计算主导情绪
  const dominantEmotion = getDominantEmotion(emotions);

  // 返回对应的Tone配置
  return TONE_TEMPLATES[dominantEmotion] || TONE_TEMPLATES.neutral;
}

function detectEmotions(messages) {
  const text = messages.map(m => m.content).join(' ');
  const scores = {};

  for (const [emotion, keywords] of Object.entries(EMOTION_KEYWORDS)) {
    scores[emotion] = keywords.filter(kw => text.includes(kw)).length;
  }

  return scores;
}

function getDominantEmotion(scores) {
  // 焦虑优先处理
  if (scores.anxiety >= 2) return 'high_anxiety';
  if (scores.excitement >= 2) return 'high_excitement';
  if (scores.confusion >= 1) return 'confusion';
  return 'neutral';
}

module.exports = { analyzeTone, TONE_TEMPLATES };
```

#### Tone注入到Prompt

```javascript
// chatController.js

const tone = await analyzeTone(history.slice(-5));

// 构建消息时注入Tone指导
if (tone.prompt_suffix) {
  messagesForLlm[0] = {
    ...messagesForLlm[0],
    content: messagesForLlm[0].content + `\n\n[Tone Guidance]\n${tone.prompt_suffix}`
  };
}
```

#### 进阶方案：Tone反馈循环

类似Tolan图1中的"Derive updated tone"：

```javascript
// 在每轮回复后，更新Tone状态
async function deriveUpdatedTone(userMessage, assistantResponse, previousTone) {
  // 分析用户对上一轮回复的反应
  const reactionSignals = analyzeReaction(userMessage, assistantResponse);

  // 调整Tone
  if (reactionSignals.satisfactionScore < 0.5) {
    // 用户似乎不满意，提高共情度
    return { ...previousTone, empathy: 'high' };
  }

  return previousTone;
}
```

---

## 八、完整实现计划（更新版）

### 阶段0: Responses API 迁移 + Rolling Summary + 可控 Context Window ⭐ (优先级最高)

**目标**:
1. 迁移到 Responses API（不使用 previous_response_id）
2. 实现 Tolan 风格的可控 Context Window，解决长对话上下文问题

**改动文件**:
| 文件 | 改动内容 |
|------|----------|
| `providers/azure/AzureLLMProvider.js` | **迁移到 Responses API**: 添加 `createResponseStream()` |
| `services/rollingSummaryService.js` | **新建** - 实时摘要生成与管理 |
| `controllers/chatController.js` | 重构消息构建逻辑，注入摘要，调用新API |
| `services/memoryService.js` | 存储和检索会话摘要 |

**核心代码变更**:

```javascript
// services/rollingSummaryService.js

const SUMMARY_THRESHOLD = 15;  // 超过15轮对话时触发摘要
const RECENT_MESSAGES_KEEP = 10; // 保留最近10轮原始消息

/**
 * 管理可控的 Context Window (Tolan 方式)
 */
async function buildContextWindow(userId, history, currentMessage) {
  // 1. 如果历史消息不多，直接返回
  if (history.length <= SUMMARY_THRESHOLD * 2) {
    return {
      summary: null,
      recentMessages: history,
      totalTokens: estimateTokens(history)
    };
  }

  // 2. 分离：需要摘要的旧消息 vs 保留的新消息
  const messagesToSummarize = history.slice(0, -RECENT_MESSAGES_KEEP * 2);
  const recentMessages = history.slice(-RECENT_MESSAGES_KEEP * 2);

  // 3. 生成或获取缓存的摘要
  let summary = await getSummaryFromCache(userId);
  if (!summary || needsUpdate(summary, messagesToSummarize)) {
    summary = await generateRollingSummary(messagesToSummarize);
    await cacheSummary(userId, summary);
  }

  return {
    summary,
    recentMessages,
    totalTokens: estimateTokens([summary, ...recentMessages])
  };
}

/**
 * 生成滚动摘要
 */
async function generateRollingSummary(messages) {
  const prompt = `请将以下对话压缩成简洁的摘要，保留：
1. 用户的主要问题和关注点
2. 达成的结论和建议
3. 关键的医疗信息（项目、预算、顾虑）

对话内容：
${formatMessages(messages)}

摘要（100-200字）：`;

  return await llmProvider.createCompletion(prompt, {
    maxTokens: 300,
    temperature: 0.3
  });
}
```

```javascript
// chatController.js 核心逻辑重构

// 1. 构建可控的 Context Window
const { summary, recentMessages, totalTokens } = await buildContextWindow(
  userId, history, prompt
);

// 2. 并行准备增强内容
const [userPersona, activeRecallMemories, toneConfig] = await Promise.all([
  memoryService.getUserPersona(userId),
  memoryService.activeRecall(userId, prompt),
  toneService.analyzeTone(recentMessages.slice(-5))
]);

// 3. 构建最终的 messages 数组
const messagesForLlm = [
  { role: "system", content: buildSystemPrompt() },

  // [Chat Summary] - 早期对话的压缩
  ...(summary ? [{ role: "system", content: `[对话摘要]\n${summary}` }] : []),

  // [User Persona] - 用户人设卡
  ...(userPersona ? [{ role: "system", content: `[用户画像]\n${userPersona}` }] : []),

  // [Tone Guidance] - 情感指导
  ...(toneConfig.prompt_suffix ? [{
    role: "system",
    content: `[情感指导]\n${toneConfig.prompt_suffix}`
  }] : []),

  // [Active Recall] - 主动检索结果
  ...(activeRecallMemories.length > 0 ? [{
    role: "system",
    content: `[相关记忆]\n${formatMemories(activeRecallMemories)}`
  }] : []),

  // [Recent Messages] - 最近的原始对话
  ...recentMessages,

  // [Current Input]
  buildUserMessage(prompt, images)
];

// 4. 调用 LLM (使用 Responses API，不传 previous_response_id)
const stream = await llmProvider.createResponseStream(messagesForLlm, {
  maxOutputTokens: 2000
});

timer.mark('开始LLM调用', { totalInputTokens: totalTokens });
```

**优势**:
- Context Window 大小可控（~3000-4000 tokens）
- 不会无限增长，成本可预测
- 符合 Tolan 架构设计
- 摘要可缓存，避免重复计算
- Responses API 提供更好的 TTFT

**AzureLLMProvider 改造**:

```javascript
// backend/src/providers/azure/AzureLLMProvider.js

/**
 * 创建响应流式输出 (使用 Responses API)
 * 注意：不使用 previous_response_id，每轮发送完整消息
 */
async createResponseStream(messages, options = {}) {
  if (!this.client) {
    await this.initialize();
  }

  const { maxOutputTokens, ...otherOptions } = options;

  const streamOptions = {
    model: this.config.deployment,
    input: messages,  // Responses API 使用 input 而非 messages
    stream: true,
    max_output_tokens: maxOutputTokens || 2000,
    // 不传 previous_response_id - 每轮重建上下文
    ...otherOptions
  };

  console.log('Azure LLM: Creating response stream with', messages.length, 'messages');
  return await this.client.responses.create(streamOptions);
}
```

---

### 阶段1: 并行化 + 主动记忆检索 (3-5天)

**目标**: 在不增加明显延迟的前提下，实现主动记忆检索

**改动文件**:
- `chatController.js` - 添加并行检索逻辑
- `memoryService.js` - 添加 `activeRecall()` 和 `synthesizeQuestions()` 方法

**核心代码变更**:

```javascript
// memoryService.js 新增方法

/**
 * 主动记忆检索 - 从用户消息合成多个检索问题
 */
async activeRecall(userId, userMessage) {
  // 1. 合成检索问题（类似 Tolan 的 Synthesize Questions）
  const questions = this.synthesizeQuestions(userMessage);

  // 2. 并行检索
  const results = await Promise.all(
    questions.map(q => this.searchEvents(userId, q, 2))
  );

  // 3. MRR 融合去重
  return this.mergeWithMRR(results.flat());
}

/**
 * 从用户消息合成检索问题
 */
synthesizeQuestions(userMessage) {
  // 基础问题
  const questions = [userMessage];

  // 关键词提取
  const keywords = extractKeywords(userMessage);
  if (keywords.length > 0) {
    questions.push(`用户的${keywords[0]}偏好`);
  }

  // 时间相关
  if (userMessage.includes('上次') || userMessage.includes('之前')) {
    questions.push('历史咨询记录');
  }

  return questions.slice(0, 3); // 最多3个问题
}
```

---

### 阶段2: Tone情感系统 (3-5天)

**新建文件**:
- `services/toneService.js` - 情感分析与风格适配

**改动文件**:
- `chatController.js` - 注入Tone指导
- `config/prompts.json` - 添加Tone模板

---

### 阶段3: User Persona 动态人设卡 (3-5天)

**目标**: 构建和维护动态的用户人设卡，类似 Tolan 的 Persona Card

**新建文件**:
- `services/userPersonaService.js` - 用户人设卡管理

**核心功能**:
```javascript
// services/userPersonaService.js

/**
 * 构建用户人设卡
 */
async function buildUserPersona(userId) {
  // 从 Memobase 获取用户画像
  const profile = await memobaseService.getUserProfile(userId);

  // 从 Supabase 获取访问统计
  const stats = await supabaseService.getUserStats(userId);

  return {
    // 基本信息
    name: profile?.extractedName || '用户',
    nickname: profile?.nickname,

    // 关注点
    primaryConcerns: profile?.concerns || [],
    interestedProcedures: profile?.procedures || [],

    // 沟通偏好
    communicationStyle: inferCommunicationStyle(profile),

    // 访问历史
    totalVisits: stats?.totalSessions || 1,
    lastTopic: stats?.lastTopic,

    // 当前状态
    emotionalState: 'neutral' // 由 ToneService 动态更新
  };
}

/**
 * 格式化为 Prompt 注入
 */
function formatPersonaForPrompt(persona) {
  const parts = [];

  if (persona.name !== '用户') {
    parts.push(`称呼: ${persona.name}`);
  }

  if (persona.primaryConcerns.length > 0) {
    parts.push(`主要关注: ${persona.primaryConcerns.join(', ')}`);
  }

  if (persona.interestedProcedures.length > 0) {
    parts.push(`感兴趣的项目: ${persona.interestedProcedures.join(', ')}`);
  }

  if (persona.totalVisits > 1) {
    parts.push(`回访用户 (第${persona.totalVisits}次咨询)`);
  }

  return parts.join('\n');
}
```

---

### 阶段4: 记忆质量优化 (持续迭代)

- 夜间压缩任务
- 记忆聚类合并
- 用户人设卡动态更新

---

## 九、参考资源

- [OpenAI Tolan案例](https://openai.com/index/tolan/) - 语音AI记忆架构
- [Meta REFRAG](https://bdtechtalks.com/2025/09/15/meta-refrag-llm-rag-optimization/) - RAG延迟优化30x
- [Sierra Voice Latency](https://sierra.ai/blog/voice-latency) - 语音AI延迟工程
- [Robylon AI Chatbots](https://www.robylon.ai/blog/how-ai-chatbots-sound-so-human) - 情感适配最佳实践
- [Dialzara Sentiment Analysis](https://dialzara.com/blog/top-7-sentiment-analysis-techniques-for-voice-ai) - 七种情感分析技术
- 图片1: Tolan对话循环架构图
- 图片2: 记忆检索与存储流程图
